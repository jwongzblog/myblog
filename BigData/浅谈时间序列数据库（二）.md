前置[浅谈时间序列数据库（一）](https://github.com/jwongzblog/myblog/blob/master/BigData/%E6%B5%85%E8%B0%88%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%88%E4%B8%80%EF%BC%89.md)，继续BB

TSDBs集中所有的精力在优化读写，如果要加上这两类预处理任务，大量的磁盘IO、cpu计算、出入内存等操作本身在集群内部会产生资源竞争，再者，如何设计恰如其分的接口让数据库系统内部知道何时触发预处理任务？openTSDB选择提供api给调用者查询和存储，自身不带任务定时调度功能，非常不负责任，而kairosDB的设计没有集群，底层存储又依赖cassandra，预聚合定时任务是把cassandra的数据读出来，计算完毕后重新写入cassandra，目前就influxDB在这块的处理优雅一点，但是集群版收费，非常贵。

锅还得自己来背，目前有如下方案解决预处理任务：
# 批处理
如同kairosDB那样，定时启动任务读取数据，聚合和降精度后重新写入数据库，取决于开发者scale的编程，但是处理时需注意几点
- 随着数据量的增加，选择从数据库读出数据再加载进内存中计算，显然不是很好的解决方式
- 随着数据量的增加，任务处理的时效性降低，花费时间越来越长，并行的workers数据协同处理非常痛苦，异常状态很难处理
- 可以尝试把数据拷贝至另一个只读系统或者生成镜像，专门供预处理使用

# stream processing
更最好的处理方式是引入流式计算系统（storm、spark、Flink），同时将一份数据分发至流式计算系统中，由这些框架去完成预计算，术业有专攻，这也是一种松耦合的设计。

就目前我们的生产环境的数据量而言，influxDB足以应对，而面对IoT类型的海量数据，建议结合stream framework和[beringei](https://yq.aliyun.com/articles/72871)。

多聊聊两句facebook开源的beringei。这个基于内存的时序数据库似乎不怎么火，我估计是时序数据库的特性实现太少了，它只提供了读写两个接口，但它比influxDB读写速度还要快，这种专注的设计我非常喜欢，一次只做一件事情，并且做到最好。更多功能特性请翻阅蚂蚁金服团队翻译的《[Gorilla：一种快速、可扩展的内存时间序列数据库](https://yq.aliyun.com/articles/72871)》

参考：

《[Gorilla：一种快速、可扩展的内存时间序列数据库](https://yq.aliyun.com/articles/72871)》---by facebook

《[技术解读：Facebook开源内存数据库Beringei，如何做到极致的压缩率](http://www.sohu.com/a/132151905_256833)》--- by EGOnetwork

《[Rollup And Pre-Aggregates](http://opentsdb.net/docs/build/html/user_guide/rollups.html)》---by openTSDB docs
